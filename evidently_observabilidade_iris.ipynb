{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092ea304",
   "metadata": {},
   "source": [
    "\n",
    "# Observabilidade e Monitoramento de Modelos com Evidently AI (Iris)\n",
    "\n",
    "Este notebook implementa um **mini-case prático** de observabilidade e monitoramento de um modelo de classificação\n",
    "utilizando o dataset **Iris**, simulando:\n",
    "- **Data drift** (mudança na distribuição dos dados de entrada);\n",
    "- **Degradação de performance** do modelo ao longo do tempo;\n",
    "- **Relatórios** do [Evidently AI](https://docs.evidentlyai.com/) para _Data Drift_ e _Classification Performance_.\n",
    "\n",
    "> **Como usar**: Execute célula a célula. É necessário ter internet para instalar o `evidently` caso não esteja no seu ambiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392449b",
   "metadata": {},
   "source": [
    "## 1. Setup do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08b0a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: pandas já instalado.\n",
      "OK: numpy já instalado.\n",
      "OK: sklearn já instalado.\n",
      "OK: evidently já instalado.\n",
      "Imports concluídos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Se precisar, descomente para atualizar pip\n",
    "# !pip install --upgrade pip\n",
    "\n",
    "# Tentativa de importar; se falhar, instala pacotes necessários\n",
    "def ensure(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"OK: {package} já instalado.\")\n",
    "    except ModuleNotFoundError:\n",
    "        # Observação: requer internet para instalar\n",
    "        import sys, subprocess\n",
    "        print(f\"Instalando {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Pacotes essenciais\n",
    "ensure(\"pandas\")\n",
    "ensure(\"numpy\")\n",
    "ensure(\"sklearn\")\n",
    "# Evidently pode não estar instalado por padrão\n",
    "try:\n",
    "    import evidently\n",
    "    print(\"OK: evidently já instalado.\")\n",
    "except ModuleNotFoundError:\n",
    "    import sys, subprocess\n",
    "    print(\"Instalando evidently...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"evidently\"])\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports Evidently\n",
    "from evidently import Report, Dataset, DataDefinition, MulticlassClassification\n",
    "from evidently.presets import DataDriftPreset\n",
    "from evidently.presets import ClassificationPreset\n",
    "print(\"Imports concluídos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f8322",
   "metadata": {},
   "source": [
    "## 2. Carregar dados (Iris) e preparar *baseline* vs *current*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3025163d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame.copy()\n",
    "df.rename(columns={c: c.replace(' (cm)', '').replace(' ', '_') for c in df.columns}, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7a17fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline shape: (75, 5)\n",
      "Current  shape: (75, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   sepal_length  sepal_width  petal_length  petal_width  target\n",
       " 0           5.1          3.8           1.5          0.3       0\n",
       " 1           5.0          2.0           3.5          1.0       1\n",
       " 2           6.9          3.2           5.7          2.3       2,\n",
       "    sepal_length  sepal_width  petal_length  petal_width  target\n",
       " 0           5.1          3.7           1.5          0.4       0\n",
       " 1           5.0          3.4           1.5          0.2       0\n",
       " 2           5.0          3.2           1.2          0.2       0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Vamos separar um baseline (referência) e um conjunto \"current\" (dados mais recentes em produção)\n",
    "# Usaremos uma partição simples. Em produção, baseline = treino/validação inicial; current = dados de produção recentes.\n",
    "baseline, current = train_test_split(df, test_size=0.5, random_state=42, stratify=df['target'])\n",
    "\n",
    "baseline = baseline.reset_index(drop=True)\n",
    "current = current.reset_index(drop=True)\n",
    "\n",
    "print(\"Baseline shape:\", baseline.shape)\n",
    "print(\"Current  shape:\", current.shape)\n",
    "baseline.head(3), current.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abca2e2",
   "metadata": {},
   "source": [
    "## 3. Treinar um modelo simples (Random Forest) no *baseline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd144b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia (baseline) = 1.000\n",
      "Acurácia (current)  = 0.893\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FEATURES = [c for c in df.columns if c != 'target']\n",
    "TARGET = 'target'\n",
    "\n",
    "X_base = baseline[FEATURES].values\n",
    "y_base = baseline[TARGET].values\n",
    "\n",
    "X_curr = current[FEATURES].values\n",
    "y_curr = current[TARGET].values\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_base, y_base)\n",
    "\n",
    "# Avaliar rapidamente no baseline e no current (antes de simular drift)\n",
    "pred_base = model.predict(X_base)\n",
    "pred_curr = model.predict(X_curr)\n",
    "\n",
    "acc_base = accuracy_score(y_base, pred_base)\n",
    "acc_curr = accuracy_score(y_curr, pred_curr)\n",
    "\n",
    "print(f\"Acurácia (baseline) = {acc_base:.3f}\")\n",
    "print(f\"Acurácia (current)  = {acc_curr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866c27b",
   "metadata": {},
   "source": [
    "## 4. Simular **data drift** e **degradação de performance** no *current*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb849d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia (baseline)        = 1.000\n",
      "Acurácia (current original)= 0.893\n",
      "Acurácia (current drifted) = 0.760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vamos criar uma versão \"driftada\" do conjunto current:\n",
    "# Estratégias (exemplos simples):\n",
    "# - deslocar/escala uma ou mais features (ex.: multiplicar 'petal_length' por 1.3)\n",
    "# - adicionar ruído a uma feature\n",
    "# - alterar levemente a distribuição (embaralhar parte dos valores de uma coluna)\n",
    "current_drifted = current.copy()\n",
    "\n",
    "# Exemplo: aumentar 30% os valores de 'petal_length' e adicionar ruído gaussiano em 'sepal_width'\n",
    "if 'petal_length' in current_drifted.columns:\n",
    "    current_drifted['petal_length'] = current_drifted['petal_length'] * 1.3\n",
    "\n",
    "if 'sepal_width' in current_drifted.columns:\n",
    "    rng = np.random.default_rng(42)\n",
    "    current_drifted['sepal_width'] = current_drifted['sepal_width'] + rng.normal(0, 0.2, size=len(current_drifted))\n",
    "\n",
    "# Prever novamente com o mesmo modelo para ver a performance após \"drift\"\n",
    "pred_curr_drifted = model.predict(current_drifted[FEATURES].values)\n",
    "acc_curr_drifted = accuracy_score(current_drifted[TARGET].values, pred_curr_drifted)\n",
    "\n",
    "print(f\"Acurácia (baseline)        = {acc_base:.3f}\")\n",
    "print(f\"Acurácia (current original)= {acc_curr:.3f}\")\n",
    "print(f\"Acurácia (current drifted) = {acc_curr_drifted:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6410a994",
   "metadata": {},
   "source": [
    "## 5. Preparar *dataframes* com predições para os relatórios do Evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7627a35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   sepal_length  sepal_width  petal_length  petal_width  target  prediction\n",
       " 0           5.1          3.8           1.5          0.3       0           0\n",
       " 1           5.0          2.0           3.5          1.0       1           1\n",
       " 2           6.9          3.2           5.7          2.3       2           2,\n",
       "    sepal_length  sepal_width  petal_length  petal_width  target  prediction\n",
       " 0           5.1     3.760943          1.95          0.4       0           0\n",
       " 1           5.0     3.192003          1.95          0.2       0           0\n",
       " 2           5.0     3.350090          1.56          0.2       0           0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# O Evidently espera termos colunas de 'target' e 'prediction'. Vamos construir tais colunas.\n",
    "baseline_for_eval = baseline.copy()\n",
    "current_for_eval  = current_drifted.copy()\n",
    "\n",
    "baseline_for_eval['prediction'] = pred_base\n",
    "current_for_eval['prediction']  = pred_curr_drifted\n",
    "\n",
    "baseline_for_eval.head(3), current_for_eval.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3806f6",
   "metadata": {},
   "source": [
    "## 6. Relatório de **Data Drift** (Evidently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af2335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatórios serão salvos em: C:\\Users\\anacl\\Downloads\\reports\n"
     ]
    }
   ],
   "source": [
    "# Cria uma pasta \"reports\" no mesmo diretório do notebook (se não existir)\n",
    "reports_dir = Path(\"reports\")\n",
    "reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Relatórios serão salvos em: {reports_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56385c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório salvo em: C:\\Users\\anacl\\Downloads\\reports\\iris_data_drift_report.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define apenas colunas numéricas/categóricas\n",
    "data_def_drift = DataDefinition(\n",
    "    numerical_columns=FEATURES,\n",
    "    categorical_columns=[],\n",
    ")\n",
    "\n",
    "ref_ds_drift = Dataset.from_pandas(baseline[FEATURES], data_definition=data_def_drift)\n",
    "cur_ds_drift = Dataset.from_pandas(current_drifted[FEATURES], data_definition=data_def_drift)\n",
    "\n",
    "drift_report = Report([DataDriftPreset()])\n",
    "drift_result = drift_report.run(current_data=cur_ds_drift, reference_data=ref_ds_drift)\n",
    "\n",
    "drift_html = reports_dir / \"iris_data_drift_report.html\"\n",
    "drift_result.save_html(str(drift_html))\n",
    "print(f\"Relatório salvo em: {drift_html.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7961c",
   "metadata": {},
   "source": [
    "## 7. Relatório de **Performance de Classificação** (Evidently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56dd73eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório salvo em: C:\\Users\\anacl\\Downloads\\reports\\iris_classification_performance_report.html\n"
     ]
    }
   ],
   "source": [
    "# (garanta que existam colunas 'target' e 'prediction' no DF de avaliação)\n",
    "baseline_for_eval = baseline_for_eval.copy()\n",
    "current_for_eval  = current_for_eval.copy()\n",
    "baseline_for_eval[\"target\"] = baseline_for_eval[\"target\"].astype(str)\n",
    "current_for_eval[\"target\"]  = current_for_eval[\"target\"].astype(str)\n",
    "baseline_for_eval[\"prediction\"] = baseline_for_eval[\"prediction\"].astype(str)\n",
    "current_for_eval[\"prediction\"]  = current_for_eval[\"prediction\"].astype(str)\n",
    "\n",
    "# mapeie tipos e papéis das colunas (features numéricas + papéis de classificação)\n",
    "num_cols = [c for c in baseline_for_eval.columns if c not in (\"target\", \"prediction\")]\n",
    "data_def = DataDefinition(\n",
    "    numerical_columns=num_cols,\n",
    "    # para Iris (multiclasse): informe onde está o alvo e o rótulo previsto\n",
    "    classification=[MulticlassClassification(\n",
    "        target=\"target\",\n",
    "        prediction_labels=\"prediction\",\n",
    "        # se tivesse probabilidades em colunas, passar prediction_probas=[\"0\",\"1\",\"2\"]\n",
    "    )]\n",
    ")\n",
    "\n",
    "# crie os Datasets com a mesma definição\n",
    "ref_ds = Dataset.from_pandas(baseline_for_eval, data_definition=data_def)\n",
    "cur_ds = Dataset.from_pandas(current_for_eval,  data_definition=data_def)\n",
    "\n",
    "# gere e execute o Report\n",
    "perf_report = Report([ClassificationPreset()])\n",
    "perf_result = perf_report.run(current_data=cur_ds, reference_data=ref_ds)\n",
    "\n",
    "# salve\n",
    "from pathlib import Path\n",
    "reports_dir = Path(\"reports\"); reports_dir.mkdir(exist_ok=True)\n",
    "perf_html = reports_dir / \"iris_classification_performance_report.html\"\n",
    "perf_result.save_html(str(perf_html))\n",
    "print(f\"Relatório salvo em: {perf_html.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9418ec2",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Interpretando os resultados\n",
    "Abra os arquivos HTML gerados na pasta `reports/`:\n",
    "\n",
    "- `iris_data_drift_report.html`: compara a distribuição das *features* entre **baseline** e **current**.\n",
    "  - Procure pelo **Overall Dataset Drift** (percentual de colunas com drift) e pelas colunas sinalizadas com drift significativo.\n",
    "  - Inspecione os gráficos de distribuição para entender **como** mudaram.\n",
    "\n",
    "- `iris_classification_performance_report.html`: compara as métricas de **classificação** entre baseline e current.\n",
    "  - Observe a **acurácia**, **precision/recall por classe** e a **matriz de confusão**.\n",
    "  - Verifique se houve **degradação** e em quais classes (espécies) ela foi mais evidente.\n",
    "\n",
    "> Dica: conecte os dois relatórios. Se houve queda de performance, **qual drift nos dados pode explicar?** Ex.: após aumentar `petal_length` artificialmente, o modelo pode confundir espécies que dependiam fortemente dessa feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3482e1",
   "metadata": {},
   "source": [
    "## 9. (Opcional) Limiares e alertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c81d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Este bloco é ilustrativo. Para extrair % de colunas com drift do Evidently, você pode inspecionar o objeto 'drift_result' em JSON ou usar APIs do Evidently.\n",
      "Aqui mostramos como você pode implementar lógica de decisão no seu pipeline.\n",
      "\n",
      "Exemplo de decisão:\n",
      "- Queda de acurácia 13.0% ≥ 10% → abrir incidente/re-treino.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo simples: defina limiares e tome decisões automáticas\n",
    "DRIFT_THRESHOLD_PCT = 0.3   # se 30%+ das colunas tiverem drift, acionar ação\n",
    "ACC_DROP_THRESHOLD  = 0.10  # se queda de acurácia >= 10 pp, acionar ação\n",
    "\n",
    "# Atenção: substitua pelos valores reais extraídos do objeto drift_result/perf_result\n",
    "pct_columns_drifted = 0.25   # exemplo didático\n",
    "acc_base_val = 0.95\n",
    "acc_curr_val = 0.82\n",
    "acc_drop = acc_base_val - acc_curr_val\n",
    "\n",
    "print(\">> Este bloco é ilustrativo. Para extrair % de colunas com drift do Evidently, \"\n",
    "      \"você pode inspecionar o objeto 'drift_result' em JSON ou usar APIs do Evidently.\\n\"\n",
    "      \"Aqui mostramos como você pode implementar lógica de decisão no seu pipeline.\\n\")\n",
    "\n",
    "print(\"Exemplo de decisão:\")\n",
    "if pct_columns_drifted >= DRIFT_THRESHOLD_PCT:\n",
    "    print(f\"- {pct_columns_drifted:.0%} das colunas com drift → acionar re-treino.\")\n",
    "if acc_drop >= ACC_DROP_THRESHOLD:\n",
    "    print(f\"- Queda de acurácia {acc_drop:.1%} ≥ {ACC_DROP_THRESHOLD:.0%} → abrir incidente/re-treino.\")\n",
    "if pct_columns_drifted < DRIFT_THRESHOLD_PCT and acc_drop < ACC_DROP_THRESHOLD:\n",
    "    print(\"- Sem ações imediatas, apenas continuar monitorando.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247a8e4",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Boas práticas para produção (checklist rápido)\n",
    "- **Log estruturado** de cada inferência (features essenciais, timestamp, versão do modelo, predição).\n",
    "- **Coleta de *ground truth*** sempre que possível (ex.: feedback do usuário, eventos de negócio).\n",
    "- **Painéis** (dashboards) com métricas de sistema (latência, erro) e de modelo (drift, acurácia, viés).\n",
    "- **Limiares e alertas** definidos e acordados entre times (DS, Eng., Produto/Negócio, Governança).\n",
    "- **Ciclo de re-treino** automatizado (ou semiautomatizado) com **validação offline** e **canary/A-B** em produção.\n",
    "- **Explainability**: monitore mudanças na importância das features e explique decisões críticas.\n",
    "- **Versionamento** de modelos e dados: rastreie o que estava em produção quando algo aconteceu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70061c6",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Próximos passos\n",
    "- Trocar o dataset para um caso de negócio seu (ex.: crédito, churn) e repetir o fluxo.\n",
    "- Integrar a geração de relatórios do Evidently num **pipeline diário/semanal** (ex.: Airflow, GitHub Actions, Azure ML Pipelines).\n",
    "- Exportar métricas do Evidently para um **Prometheus/Grafana/Datadog** e criar **alertas**.\n",
    "- Adicionar **avaliações por segmento** (ex.: performance por região/faixa etária) para capturar problemas localizados.\n",
    "- Incluir **testes de qualidade de dados** antes da inferência (valores faltantes, ranges, tipagem).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
